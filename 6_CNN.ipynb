{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeminq1/python_ai_colab/blob/main/6_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwg3JWBQZuNt"
      },
      "source": [
        "### CNN (Convolutional Neural Network)\n",
        "#### - for images!\n",
        "#### - inductive bias for localization + weight sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRXhGVcBcOsz"
      },
      "source": [
        "### 1. Classification on MNIST dataset\n",
        "#### - use Conv layer to extract feature map from images\n",
        "#### - use dense layer to make scores for each class\n",
        "#### - use softmax activation at the end of network to produce \"probability\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvUUxKErcP1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6455db19-e704-452d-b3c8-5f8bdd115399"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Download MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# calculate the sample mean and std\n",
        "# calculate the sample mean and std\n",
        "mu = X_train.mean()\n",
        "# 0으로 나누는 것을 방지하기 위해서 매우 작은 값을 더해준다.\n",
        "sig = X_train.std()+0.000000001\n",
        "\n",
        "# normalize (z-score)\n",
        "X_train = (X_train - mu) / sig\n",
        "# print(X_train[0])\n",
        "\n",
        "# train set과 동일한 평균과 표준편차로 test_set도 변경해줘야한다.\n",
        "\n",
        "X_test = (X_test - mu) / sig # note! : use the same statistic with the training set!\n",
        "\n",
        "\n",
        "# Change the shape of data from (W, W) to (W*W, )\n",
        "# 여기서는 마지막에 1은 흑백사진이므로 채널을 맞춰주기 위해서 써준다.\n",
        "X_train = X_train.reshape((-1, 28,28,1))\n",
        "X_test = X_test.reshape((-1, 28,28,1))\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices (https://www.educative.io/edpresso/how-to-perform-one-hot-encoding-using-keras)\n",
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[[-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.38589016 -0.1949715  -0.1949715  -0.1949715   1.17964286  1.30692197\n",
            "   1.80331049 -0.09314822  1.68875929  2.82154335  2.71972006  1.19237077\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.04223657  0.03413089  0.77234972  1.53602436\n",
            "   1.73967093  2.79608752  2.79608752  2.79608752  2.79608752  2.79608752\n",
            "   2.43970602  1.76512675  2.79608752  2.65608051  2.0578687   0.39051239\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389  0.19959373  2.60516886  2.79608752  2.79608752  2.79608752\n",
            "   2.79608752  2.79608752  2.79608752  2.79608752  2.79608752  2.7706317\n",
            "   0.7596218   0.61961479  0.61961479  0.28868911  0.07231462 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.1949715   2.36333856  2.79608752  2.79608752  2.79608752\n",
            "   2.79608752  2.79608752  2.09605243  1.89240586  2.71972006  2.6433526\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389  0.59415897  1.56148018  0.93781256  2.79608752\n",
            "   2.79608752  2.18514781 -0.28406688 -0.42407389  0.12322627  1.53602436\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.24588314 -0.41134598  1.53602436\n",
            "   2.79608752  0.72143807 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389  1.3451057\n",
            "   2.79608752  1.99422915 -0.39861807 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.28406688\n",
            "   1.99422915  2.79608752  0.46687986 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "   0.02140298  2.6433526   2.43970602  1.61239182  0.95054047 -0.41134598\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389  0.60688688  2.63062468  2.79608752  2.79608752  1.09054748\n",
            "  -0.10587613 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389  0.14868209  1.9433175   2.79608752  2.79608752\n",
            "   1.48511272 -0.0804203  -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.22042732  0.7596218   2.78335961\n",
            "   2.79608752  1.95604541 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389  2.74517588\n",
            "   2.79608752  2.74517588  0.39051239 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389  0.16141     1.2305545   1.90513377  2.79608752\n",
            "   2.79608752  2.21060363 -0.39861807 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "   0.07231462  1.4596569   2.49061767  2.79608752  2.79608752  2.79608752\n",
            "   2.75790379  1.89240586 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.11860404  1.02690793\n",
            "   2.38879438  2.79608752  2.79608752  2.79608752  2.79608752  2.13423617\n",
            "   0.56870314 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.13133195  0.41596821  2.28697109  2.79608752\n",
            "   2.79608752  2.79608752  2.79608752  2.09605243  0.60688688 -0.39861807\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.1949715   1.75239884  2.36333856  2.79608752  2.79608752  2.79608752\n",
            "   2.79608752  2.0578687   0.59415897 -0.3095227  -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389  0.2759612   1.76512675\n",
            "   2.45243393  2.79608752  2.79608752  2.79608752  2.79608752  2.68153633\n",
            "   1.26873823 -0.28406688 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389  1.30692197  2.79608752\n",
            "   2.79608752  2.79608752  2.27424318  1.29419406  1.25601032 -0.22042732\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]\n",
            " [-0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389 -0.42407389\n",
            "  -0.42407389 -0.42407389 -0.42407389 -0.42407389]]\n",
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## data sample\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "plt.imshow(X_train[0].reshape(28,28))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUu4rp-eLwsn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9a4810e0-33a4-4694-e597-0892167efbfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTEgUbPk9o2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79886046-286c-40d5-ba1a-88c1e73a6f73"
      },
      "source": [
        "## Model (https://keras.io/api/layers/)\n",
        "## 2-layer CNN with MLP\n",
        "# check the #parameters! (only 10% of MLP)\n",
        "# filter의 갯수만큼 output의 갯수가 나옴 , 여기서 filter는 동일 (3,3) 짜리 필터의 갯수를 몇개쓸것인가에 대한것임\n",
        "# pooling layer를 쓰는 이유는 demesion reducton과 max값인 것이 예측하는 데 더 많은 정보가 들어있다고 생각함\n",
        "\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "      keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3,3),\n",
        "        strides=(1, 1),\n",
        "        padding=\"valid\",\n",
        "        activation='relu',\n",
        "        input_shape=(28,28,1)\n",
        "      ),\n",
        "      keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3,3),\n",
        "        strides=(1, 1),\n",
        "        padding=\"valid\",\n",
        "        activation='relu',\n",
        "      ),\n",
        "     keras.layers.MaxPooling2D(\n",
        "       pool_size=(2, 2), strides=None, padding=\"valid\"\n",
        "       ),\n",
        "     layers.Flatten(),\n",
        "    #  hidden layer를 써도 됨\n",
        "    #  layers.Dense(100,activation='relu'),\n",
        "     layers.Dense(10,activation='softmax')\n",
        "    ],\n",
        "    \n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                46090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,658\n",
            "Trainable params: 55,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzW1cFaD-xP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57eb1000-6f58-44e5-c673-abcd2afcd42f"
      },
      "source": [
        "## Train (https://keras.io/api/models/model_training_apis/)\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "## compile\n",
        "# 러닝 rate / loss / optimaizer 머 쓸건지 정함\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) # keras.losses.MeanSq\n",
        "## fit\n",
        "hist = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "844/844 [==============================] - 18s 10ms/step - loss: 0.1556 - accuracy: 0.9546 - val_loss: 0.0641 - val_accuracy: 0.9842\n",
            "Epoch 2/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0527 - accuracy: 0.9835 - val_loss: 0.0495 - val_accuracy: 0.9857\n",
            "Epoch 3/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.0455 - val_accuracy: 0.9878\n",
            "Epoch 4/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
            "Epoch 5/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.0495 - val_accuracy: 0.9880\n",
            "Epoch 6/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0617 - val_accuracy: 0.9863\n",
            "Epoch 7/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0487 - val_accuracy: 0.9885\n",
            "Epoch 8/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0535 - val_accuracy: 0.9903\n",
            "Epoch 9/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9887\n",
            "Epoch 10/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0568 - val_accuracy: 0.9890\n",
            "Epoch 11/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0541 - val_accuracy: 0.9902\n",
            "Epoch 12/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0622 - val_accuracy: 0.9893\n",
            "Epoch 13/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0687 - val_accuracy: 0.9888\n",
            "Epoch 14/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0642 - val_accuracy: 0.9882\n",
            "Epoch 15/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0753 - val_accuracy: 0.9887\n",
            "Epoch 16/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0750 - val_accuracy: 0.9900\n",
            "Epoch 17/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0633 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0789 - val_accuracy: 0.9892\n",
            "Epoch 19/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0922 - val_accuracy: 0.9885\n",
            "Epoch 20/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0745 - val_accuracy: 0.9905\n",
            "Epoch 21/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0806 - val_accuracy: 0.9890\n",
            "Epoch 22/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0844 - val_accuracy: 0.9903\n",
            "Epoch 23/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0729 - val_accuracy: 0.9885\n",
            "Epoch 24/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0761 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0726 - val_accuracy: 0.9907\n",
            "Epoch 26/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0886 - val_accuracy: 0.9887\n",
            "Epoch 27/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0868 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0929 - val_accuracy: 0.9900\n",
            "Epoch 29/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0861 - val_accuracy: 0.9903\n",
            "Epoch 30/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1034 - val_accuracy: 0.9893\n",
            "Epoch 31/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1109 - val_accuracy: 0.9892\n",
            "Epoch 32/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1016 - val_accuracy: 0.9890\n",
            "Epoch 33/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1046 - val_accuracy: 0.9900\n",
            "Epoch 34/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0958 - val_accuracy: 0.9892\n",
            "Epoch 35/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1105 - val_accuracy: 0.9890\n",
            "Epoch 36/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1056 - val_accuracy: 0.9902\n",
            "Epoch 37/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1025 - val_accuracy: 0.9905\n",
            "Epoch 38/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.1368 - val_accuracy: 0.9880\n",
            "Epoch 39/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0999 - val_accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 2.2669e-04 - accuracy: 0.9999 - val_loss: 0.1122 - val_accuracy: 0.9907\n",
            "Epoch 41/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0917 - val_accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1120 - val_accuracy: 0.9897\n",
            "Epoch 43/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1158 - val_accuracy: 0.9883\n",
            "Epoch 44/50\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1085 - val_accuracy: 0.9890\n",
            "Epoch 45/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 6.8112e-04 - accuracy: 0.9997 - val_loss: 0.1211 - val_accuracy: 0.9892\n",
            "Epoch 46/50\n",
            "844/844 [==============================] - 9s 11ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1115 - val_accuracy: 0.9897\n",
            "Epoch 47/50\n",
            "844/844 [==============================] - 12s 14ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.1163 - val_accuracy: 0.9892\n",
            "Epoch 48/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1169 - val_accuracy: 0.9890\n",
            "Epoch 49/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1081 - val_accuracy: 0.9900\n",
            "Epoch 50/50\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1024 - val_accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TruvpcHI9Pv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cb26d777-074d-4147-a139-9bddb57f7fbf"
      },
      "source": [
        "## plot loss and accuracy to check if the model is converged.\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "train_accuracy = hist.history['accuracy']\n",
        "\n",
        "# x축을 epochs\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(np.arange(epochs),val_accuracy,label=\"val_accuracy\")\n",
        "plt.plot(np.arange(epochs),train_accuracy,label=\"train_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVf7H8fc3PUDoEEqAIEVaSIAQUKQooqiIigJiQxHdte0q21D3p6xl1V13XfsKAoqiroIFUFAREBslQXonBEhCQkjvZeb8/riTkEASUgm58309zzwzc9ucO5l85sy5554rxhiUUkrZl0dDF0AppVT90qBXSimb06BXSimb06BXSimb06BXSimb82roApyubdu2Jjg4uKGLoZRSjUpUVNRJY0y78uadd0EfHBxMZGRkQxdDKaUaFRE5UtE8bbpRSimb06BXSimb06BXSimb06BXSimb06BXSimbO2vQi8gCETkhIjsrmC8i8oqIHBSR7SIyuNS86SJywHWbXpcFV0opVTVVqdG/A4yvZP5VQC/X7V7gTQARaQ08CQwDIoAnRaRVbQqrlFKq+s4a9MaY9UBKJYtcBywylg1ASxHpCFwJfGuMSTHGpALfUvkXhlLK3TkdsPNT2PU5FOU3dGlsoy5OmOoMHCv1PNY1raLpZxCRe7F+DdC1a9c6KJJSqlExBg58A98+CUl7rGn+rSF0Ggy+Hdr3LX89pxNSoiE3BTqHg0cVGikKc2HXZ5AeC4U51vOS+1zwbwWdB0PnIdC+H3h6191+no2jCDzr/jzW8+LMWGPMXGAuQHh4uF4JRamqKMyDjDjrlh5r3YryoF1f6DAA2vSqODScTshKcIVdLhiHNc1Z5HpcBF5+4NMMfJuBbwD4BFiPvfxA5MxtOoqgIBPyMyE/y7ovyISiAmh3IbTqXn4Qx0VZAR/zA7S+ACa/a73OlkWwaS5seB2CImDwHdApDBJ2wvFt1i1hOxRkWdtpeyFc/CCETAFvvzNfJz8LIhfAL69BVqI1zcMbvJuAt/+pW+Zx+PU9a76XH3QIgU6Drfe0eScI6AQBHawvhNLvQ34WpB2B1CPWfXosePpY++ITYL2Hvs3ApynkpZ/6m6XHQvox675dH7jrq6p/BqqoLoI+DuhS6nmQa1ocMOa06evq4PWUKssYSD0MMT/BkZ+se09vuPQx6D+parW80pwOiPkRdnwCe7+EgI7Qa5x16zKs/BqeoxBO7IH4LVYNM79U4BVkQX6Gtd2WXa0wa9PDum/dA5p3rryMBdnWthN2QOIuSNwJyYcg+8SZy4qnFdQAnr5WwHYIgVbBkJlQKoiOguMcN434BEDHgdAx1Lq17Aab58HOpdCkLVz9Igy589T72/NyyEqC7R/Blvdg2YOntuXdBAIHWDX+jqEgHrDxTVj2EHz3NAz7DQy92wrj3FTYONean5sK3UfDpHnQ7eLy/5bFn6e4LRD/q3X/63tWrb80L38r8P2aQ3oc5JwsO9/T99SXZoXvSTNo0QVaBJ36MqkHUpVLCYpIMLDCGHNGKUTkGuBB4GqsA6+vGGMiXAdjo4DiXjhbgCHGmMra+wkPDzc61s15JmGH9c/j5WMFU+mQCuhQfu2uIllJsH8VOArAOK3wK65FglXr8WsJfi3Av6X12Le5VVPNS4PcNOs+L936pz2+3QrlzHhr/SZtoNsISDkMiTugYxhc8TR0H1V5uYyxQnrHUit4shKsYOp9pVX7O/qLVU7f5nDBaOh1hVXbi4uygiBhu1VGcNXimp9ZkxMPK2RTosuGrKePtUyZmmUT8PKFtGPW8rj+T30CILA/tO1lfWm0CDp1a94ZEEg+YNV6E11fDAk7rS8Fv5bQqpsVsK2CTz32bgIentaXhIcHeHhZj4vyXTX04tq5676itnMPT9cvgICy++7haX1RldTCd0BRrrWOl79VC7/4d1ZgVvb3ObbJqvl2CIE2Pa3tnr5M9Dr4+VU49B14N7W+nA9+Z+1H76tg5B+gy9DKPwvlcRRBRixkHLc+a5kJkBFv1f7z0q33vvR727IbNG1rrVuU5/rCL/XF79vc+pv5taje/08lRCTKGBNe7ryzBb2IfIhVM28LJGL1pPEGMMb8V0QEeA3rQGsOcJcxJtK17gzgMdemnjXGLDxbYTXozyNOp1ULWj3H+mD6t4LUGHAWnlrGuymE3gxXPAM+TSrfXmwU/O9W65+jrjRtD8EjrHAPHmnVYEWssu/42PqCyoi1gvnyv0FgP2u9vAwrcIrD59hGqxbn6WMtGzLZCnlv/1PLH/4eDnxr3Yq/WLz8reaEToNd7bqDrSaKyv55nU6ruSUlGlIOWeFfkHWqrbgg51SbcUAHK9gCB1i1vRZdq/8LBaxtFe9LQ3MUQfJBSNpr/UJq3rHuXyNhp9VEs2e5FfYj/2C9jzZWq6A/1zTozxOZCfD5fXBoDVx4NUx8DZq2sWrg6cespoOUaIjfClsXQ9veMHmhVdssz6+LYcUjEBAIk962aqMeXlatrLg2CVaNsaTmnu6qvWdYba6n1/T9Wpy9RlSYB5vegvX/smpU3Ue5asmHTi0T0NGq+fe5Bvpea22/MsZYIeV0WG2q9XDwTKnq0qBX1bNvFXxxv1WzvPJZCJ9ReZgeWgOf/dYK5yufhaEzTy3vKIRv/gob/2uF7OR3oUnrc7MfpeWkwA//smrj7Xq72onDoMNA68tHqUZOg97u8rOsn8LFR/AzSh3N9w2wArb7aCvcTm/XLFaYByf3WT0dNr8NgSFw03yrKaQqspLg89/CwdXQZwJMfNVqg//kTqs3xfD7YdzTWvtVqp5o0NtZ8iGYf0XZI/6evq4DdJ2tAC7ul+zXwmrH7j7KOmB0Yvepg3Un9586IDr8Abj8SetgYHU4nbDhDatNv1l7qzkmKxGufRnCptXF3iqlKlBZ0Gv1qjHLTYUPplg155sWWuHdoot1tL90U0tmolWrjl4Hh9fD3hWn5rXoYrWr97nGuu80CFp3r1l5PDysHhTBI2DJDOtXwoyV1oknSqkGozX6xspRCItvsvqMT19m9QmuqtQYq5tY+z5WT5r6Kp/TUf6JK0qpOqc1ejta9ahVQ5/4WvVCHlx9qIProVCleHqf21PHlVIV0vHozydOh1XbPr7d6sJXkU3zrDMKL37IGgdEKaUqoTX6hpKdDNFrrYOgJ/fDyQNWz5nisyvb9ra6KYbebB1ELXZoDaz8C/Qeb50ApJRSZ6FBf64ZA1s/gG8etw6miofVjNK2N/S41LoHiHoHVv4ZVv8NBk6BiHusszY/udPq8njj2xV3lVRKqVI06M+llGhY/rB1Kn2X4dbJRR1Cyu/GOPgOawyVzfNh24cQtdAabsDbH6Z9ZPWPV0qpKtCgPxcchda4G+uet2rl1/wbhtx19jFLisdOueJpa5iBvV/BuL9ZgycppVQVadDXt+Pb4IsHrAG0+kyAq/9pjWldHU1aWwdeL36ofsqolLI1Dfr6lLQP3plgDQM75T3oN7GhS6SUckMa9PUlJwU+mGq1v89cDS27nH0dpZSqBxr09cFRaPWOyYiD6Ss05JVSDUqDvj6setTqWXP9m9B1WEOXRinl5vTM2Lq2ef6ps1bDbmno0iillAZ9nTq83jrJqfiydUopdR7QoK8rKdHw8R3WBbP1rFWl1HlEg74u5KbCh64La0z7sOzYNEop1cD0YGxtFeTABzdbNfrblkKbHg1dIqWUKkODvjaKu1Ee2wiT37Eu0aeUUucZDfqacjrhiwfhwNcw4SXof31Dl0gppcqlbfQ1YQx8+3+w/SO49K8QPqOhS6SUUhXSoK+Jn162RqOM+A2M+mNDl0YppSqlQV9dW96D1U/CgJtg/PMg0tAlUkqpSmnQV8e+lbD8d9BjrDW8wdnGk1dKqfOAJlVVxUbBJ3dBx1CYsgi8fBq6REopVSUa9FWRfAg+mAIBgXDLx+DbrKFLpJRSVaZBfzbZJ2HxTWCccOtSaNa+oUuklFLVov3oK1OQY108JCMepi+Htj0bukRKKVVtGvQVcTpg6d0QFwVT34cuEQ1dIqWUqhFtuimPMfDVn2DfV9bFvPtOaOgSKaXcQJHDWS/b1aAvT9Q7EDkfRvweIu5p6NKoBpRf5MAY09DFcCtFDidOp3u954kZeTzyv63M+nhbvWy/SkEvIuNFZJ+IHBSR2eXM7yYi34nIdhFZJyJBpea9ICI7XbepdVn4epGTAqvnQPBIGDunoUujgMiYFDLzCs/pa+YVOnh59QFC//YNz63ce05fu7EpdDjZeiyNDdHJtdrOyax8Xvx6H4Of/pZLXljD/B8Pk51fVEelPD/lFzl4c90hLn1xHV9uP07X1k3qpWJx1jZ6EfEEXgfGAbHAZhFZZozZXWqxF4FFxph3ReQy4DngdhG5BhgMhAG+wDoRWWmMyajrHakza5+F/Ay46oV6PSHq54Mn2X08g7sv6Y7o2bUVWrnjOPct3kJol5YsnjmMZr5nP6z09a4EEjPyuOOi4Gq/njGGVTsTeObLPcSl5dK9bVPmro9mRM+2jO7drgZ7UD6n07D/RCabY1I5mJjJ5PAuDOjcOK5jkJlXyJajaUTFpLA5JpVfj6WSV2g1OXx6/8UM7tqqWts7lpLDvB+i+d/mYxQ4nFzRL5C0nEKeXrGbV9ccYPpFwUy/OJjWTe117sqavYk8tXw3Mck5jOsXyF+v6Uu3Nk3r5bWqcjA2AjhojIkGEJGPgOuA0kHfD5jlerwW+LzU9PXGmCKgSES2A+OBj+ug7HUvYSdELoChMyGwf729zIHETGYuiiSnwEF+kZMHLq15b55DSVn84eNt9A5sxp+u7EO7AN86LOnZpecUklVQRGCAL16edfvFeDw9l9mf7iC4TRN2xqVz9zubeeeuCPx9Kr5616JfYnjii10ANPXx4sYhQRUue7r9iZnMWbaLnw8l06dDAB/eM5xBXVty7as/8sdPtrHq9yNp06z676/TaTiZnc/hpGwij6QSGZNC5JFUMvOs2qqXh7B441FmXdGb34zqgadH3X7xG2M4np5Hp5b+tdpOTkERj366g+Xb4nEa8BDo16k5Nw/tyuBurXh6xW6eWr6bz+6/uEqVl30Jmby57iDLtx/HQ2DSoCDuHX0BPdpZ56lEHUnlv98f4uXvDjB3fTQ3R3Rh+kXBdGvTpFFXjqKTsnh6xW7W7kuiR7umLJoRwag6rESUpypB3xk4Vup5LDDstGW2AZOAl4EbgAARaeOa/qSI/AtoAlxK2S+I84cxsGo2+LWEMY/W28tk5Rfx2/ejaOLjySU92/LPr/cR3KYp1wzsWO1trdt3goc+/BUPEXbFp7NyRwK/v7wXd1wUjI9X/R9++eVQMjPf3Ux2gQMPgQ7N/ejY0p9OLf3p1NKPQV1aMq5fhxoFl9NpmPW/bRQ6nCy8K4LtsWk8/L+t3Lc4irm3h5+xf8YYXl97kBe/2c+4foFk5hXy2Gc76NuxOf06Na/0tfIKHTy/ci/vbThCM18vnrquP7dEdC354npl2iCue+0n/rJ0B/PuGFJpyBxIzGT5tnji0vKIT8slPj2X42l5FJQ6yNarfTMmDOzE0OBWDA1uTYCfF49/tpN/rNrHur1J/GtKKF1aN6n2e1aepMx8/rJ0O2v2nmBcv0D+75p+dG1T/W3HpuZwz6Io9iVkMGNEd8Zc2J6wri3L/MLKK3Tw5yXbWbYtnuvCOle6vR2x6Ux68yd8PD2YMSKYuy+5gA4t/MosM6RbK+bdEc6BxEz++3007/1yhIU/xdChuR/hrvcuPLgVfTo0r/Mvx/rgdBre+TmG51ftxdfTg79e05fpFwfjXccVpPLI2dqDROQmYLwxZqbr+e3AMGPMg6WW6QS8BnQH1gM3AgOMMWki8jgwGUgCTgCbjTH/Oe017gXuBejateuQI0eO1NHuVcOuz+GT6XDNv6wafT0wxvDgB7+ycudx3p85jMFdW3Hb2xvZEZfOh/cOr/JPXmMMb/9wmOdW7uHCDs2Zd8cQCoqcZWoJT1zbv06bGk63enci93+whW6tm3DXiO4kpOeWG27BbZrwm9E9mDS4M75eVb+O7lvfH+K5lXv5x40DmTK0CwAfbTrK7E93cNWADrw6bVBJEBtjeG7lXuauj+aGQZ35x00DScspZMKrP+Dn7cmyBy+hhb93ua+TlV/EzHc3s/FwCrcO68ofxl1Iq3KaCOb/eJinV+zm2RsGcOuwbuVua+WO48z6eBv5RQ4Cm/u5vvCsL73OLf3p0roJYUEty92+MYbPfo0r+TXy1HX9uWFQ51rVXFfvTuQvS7eTmV/EDWGdWb49niKn4d6RF3D/pT1o4lO13tWbDqdw3/tRFDicvDptEGMuLP+kQafTcO1rP5KSXcCaP4yp8JdXTkERE175kZwCB8sfuqTKv0Lj03L5bk8im2NS2RyTwvH0PACa+Xoxomcbnr0hhLY1+MVVGWMMu+IzWL4tnhOZ+VzZP5AxF7bHz7t614ROzMjjj59s44cDJxnbpz3P3RhC+wC/s69YDSISZYwJL3deFYL+ImCOMeZK1/NHAYwxz1WwfDNgrzHmjN/MIvIB8L4x5quKXi88PNxERkZWWqY6V5gLr0WAX3P4zfp6u7D32z9E88yXe5h9VR9+O9q65GByVj43vPEzOQVFfHb/iLPW5PIKHTz22Q4+3RLH1SEdeHFyaJl/2NLtfpf3DeQv4y+kV2BAne7HF1vjmPXxNgZ0as47d0WUG1wOp+GbXQm8se4QO+LSaR/gy4xLunPrsK4E+JUfusV2xqVzwxs/cXnfQN64dXCZsCsO3EmDO/PiTaEY4PHPdvDR5mPccVE35lzbHw9X7S7qSApT39rAmAvbM/f2ISXTi6VmF3Dnwk3sjM/g31NCK62FOp2G6Qs3sTkmhRUPjaRn+2Zl5r383QFe/u4Ag7q25K3bhtC+ec3+iY+l5DDr461sjknlmoEduWfkBXRu6U/bZj5VDv2cgiKe+XIPH2w8St+OzXn55jB6BwaQmJHH8yv38tmvcXRo7sdj1/Tl2oEdK93uh5uO8n+f76Rr6ybMmx5e0qxSkY3RyUydu4FZ43rzu7G9yl3m0U938NHmoyyeOYyLe7St0j6VJy4tl8iYFDYdTmHpllg6tfTn/buH1bqJCiDmZDbLtsXzxdY4DiVl4+UhBPh5kZpTSICvF+MHdOC6sM5c1KPNWX9NfLXjOI99toO8Qgf/N6Eft0R0rZemp9oGvRewHxgLxAGbgVuMMbtKLdMWSDHGOEXkWcBhjHnCdSC3pTEmWUQGAh8AYa42+3I1SNCvewHW/R3u/BKCL+FQUhZr957g9ou6VasWWplNh1OYNm8DY/u0563by/78P3gii0lv/ERgcz+W3n8xzSsIwhMZedz7XhRbj6Uxa1xvHrqsZ7kfmPwiBwt/iuHV7w6QXeAgpHMLrgvrxISBnc74eVxd7204whNf7GRY99a8PX3oWQ+OGmP4+VAyb647xI8HTxLg58Xtw7tx14ju5dbkcgqKmPDqj+TkO1j18EhaNjnzS+Tl1Qd4afV+bhveldScQr7cfpyHLuvJrHG9z3g/Fv50mL8t382frrywzLGQxIw8bnt7I0dScnjjlsFc3i/wrPt+IiOPK/+znk4t/fn0/ovx9fIkO7+IP3y8jVW7ErhpSBDPXD+g2rW90zmchrfWH+Lf3+ynyNXN0MfLg04tSv9K8Kdzy1LPW/jj7+PJ1mNpPPK/rcQkZ3PvqAuYNa73GZ/hyJgU5izfxc64DIYGt2Js38Ay22sf4IfTGJ5esZtFvxxhVO92vDptUIW/ik53/+Io1u5NYu0fx5zxeVu1M4Hfvh/Fb0ZfwKNX9a3V+1Ta5pgUZizcTHN/b96fOYzubat2UDO3wEF8eq71SzQtl9jUXNYfOMm2Y2kADOvemuvCOnPVgA4E+HnxS3QyX2yNZ9XOBLLyi2gX4MuV/QO5oG0z13to/YJr3dSHrPwi5izbzdItsQwMasFLU8PO+kVZG7UKetcGrgb+A3gCC4wxz4rIU0CkMWaZq3nnOcBgNd08YIzJFxE/YItrMxnAb40xWyt7rXMe9GnH4LWh0PtKmPIu22PTmL5gE6k5hYR3a8Wbtw2p9QHOE5l5THjlR5r6evHFgyPKDfKfD57kjgWbuKhHGxbcORRvTw+MMcSm5rLZ1bvh290J5BQ4+PeUMMYP6HDW103KzOeLrXEs2xbP9th0RGB49zZcF9aJqwZ0pEWTqv3jFnt97UH++fU+Lu/bntduGVztQNsem8ab6w6xalcC3p4eTAkP4t6RPcq0GT/22Q4+3HSUxXcP4+Ke5df2SjfVADx2dR/uHVX+RdmNMfzuo618uT2e9+4exoiebTmanMOt8zeQklXA29OHclGPNlXeh292JXDve1H8ZtQF3Da8G/csimR/YiaPXd23zntQHUvJYW9CZkkIxZW6P5GZz+n/uq2b+pCeW0hggC//mhJW6X45nIZPIo/xn9UHSMjIKzPP01V7Tcsp5J6R3Zl9Vd9qtYEfS8lh7L++Z0JoR/49JaxkeqLrizKolT+f3jeizo8j7YxL544Fm/AQYdGMiHKPzTidhm92J/LOz4fZn5hFSnZBmfkeAn07Ni+pGFX06yCv0MHavSf4Yms83+9PIrfQUWa+r5cHPl4eZOcX8eClPXlobK96b4uvddCfS+c86D+50xpn/sHNbEhpysx3I2nh783Mkd15YdVeWjfxYe4d4TXu+lbocHLr2xvZHpvG5w+MoE+Hig8Mfrz5GH9eup3L+wbi6+1BZEwKiRn5AAT4eRHerRV/Ht+Hvh0rP7hYnuikLJZti2fZ1niiT2bj5+3BzUO7MnNkd4JaVd5clJFXyKvfHWDeD4e5LqwTL04OrdWHNjopi7nro1m6JRaH0zBhYCd+O7oHsak5JSH66NWV1/aMMby1PpqOLfzOeuAvO7+I61//ieTsAl6aGsafPtlGgcPJu3dFENqlZbXL/9hnO/hg41Fa+HvjNIbXbhlcr8dDylPocJKQfuqYSLzr+Ii/tycPXdarWl/imXmFHE/PIy7NOrYSn5bL8fQ8Rl/YjomhnWpUvhdW7eXNdYf44oERhHZpidNpuGPBJiKPpPDl70bWW8324Iksbp+/kez8IhbeNZQh3VoDUFDk5POtcbz1/SEOJWXTpbU/I3u1K6mBd2rhT+dW/gQ296v2Z9sYQ2pOYZkv4/i0XFKyC5kW0YXw4Nb1satn0KCvSMyP8M41MHo2azrO4L73t9CldRPev3sYHVr4sTMunXsXRZKSU8CLk0OZMLD6H/rnvtrDW+uj+c/UMK4fVHkgAfzz6728vvYQnVv6Ex7civBurQgPbk3vwIA66VlgjGFHXDrv/XKEz7fG4TQwMdQK2gs7nGrLzyt0sG6fVWP5bu8JCoqc3Da8K09NHHBGW3dNJaTnseCnwyzecITsAgc+Xh70at+Mz+6v+9rewRNZXPfaj2QXOGgf4Mv7M4fRu4bHLnIKirjh9Z8pdDp5+45wLqjHn+ONVWZeIZe++D3BbZrwyW8vYv6Ph3nmyz38/YYQbhnWtV5fOzY1h9ve3khiRj7/uTmMYyk5vP3DYRIy8ujXsTm/HdODqwd0qPPuwA1Ng74iiydDwk5WjF7Ow5/up2/H5rw7I6LMiRlJmfnc934UkUdSefBSqx24qkEXGZPC5Ld+YVpEV/5+Q0iV1jHGkJZTWO4Bzrp2PD2X+T8c5oNNR8kpcDC2T3smhnXixwMnWbUzgcz8Ito282HCwE5MDOvEoC4t6+UgUnpOIe9vPMKavSd44caBZQ501qXVuxNZ+PNhnrthYI26GJaWX+TAy8OjUXTrayjFvaQevLQnc9dHM/rCdsy9vfLuqXUlKTOf2+dvZG9CJgDDL2jNfWN6MqpX20bdB78yGvTlKciBf3RnT9BNXL3vaoYGt2b+9PBye4TkFzl44vNd/C/yGOP6BfLKzYMqPWkHrBrx1S//QIHDydcPj6JpFc7obChpOQUs+uUIC386TGpOIc18vbiyfweuH9SJiy5oY7uajzo3HE7DhFd/ZM/xDNoH+LLq4VHn9OzW9JxC5v90mDEXtqv22bqNkQZ9efZ/Ax9M5raCR/HpPZY3bq384KIxhnd/juFvK3ZzZb8OvHHr4Epr9s+t3MNb30ezeKZ1ALAxyC1wsCMunYFBLWrdc0QpsHqbPfDBFl6aEsYlvRrH/0FjVVnQn7/VzHqWtn0FPsaXJr1G8vrtQ856AEZEuHNEdxwGnl6xmxe+3lth97Btx9KYtz6aaRFdGk3IA/j7eBLR/dwcOFLuIaJ7azY9Nta2zSWNhVsGvcPhJH/3Kn6VEJ69KbxaR9lnjAgm5mQ2b30fTXCbpkyLKHtgKb/IwZ+WbKN9gN9Ze44o5Q405BueWza+fvrtWgKdibQaeHW1+8iLCE9e24/Rvdvxf5/v5McDJ8vMf33tIfYnZvH3SQMqPPFJKaXOJbcL+piT2Rz6+TMAQi+9qUbb8PL04LVbBtGjXTPuWxzFgUTryP7u+AzeWHuQSYM6c1mfs59pqZRS54JbBb3TafjL0u2Mka0UtrkQaVX+4FRVEeDnzfw7w/H18mTGu5tJzMjjT0u20bKJD09c268OS62UUrXjVkG/eNNRdh6OY6jHHrwvvLLW2wtq1YT508NJysznyv+sZ1d8Bs9cP6Dc8VmUUqqhuE3Qx6bm8PxXe7in81E8TRH0uqJOthvapSX/mRpGWk4h14R0rNIYNEopdS65Ra8bYwyPfroDgJkdD0JmAHQdXmfbHz+gI988MoputTzbUiml6oNb1Og/iYzlhwMnmT3+QpodWQs9LgXPuu0R0zswoM6GNFZKqbpk+6CPjEnhyWW7iOjemlu7Z0FmfJ012yilVGNg66DfGZfOXQs307GFH6/fMhiPg99aM3pe3rAFU0qpc8i2QX8gMZPb528sueJMuwBfOPAtdBgIzat/IW6llGqsbBn0R5KzufXtjXh5erB4pusakrmpcGyjNtsopdyO7YL+eHout8zbSKHDyeKZwwguvnbkobVgHBr0Sim3Y6ugP5mVz61vbyQjt5BFM067gtDB1eDfCoLKHcVTKaVsy5MW7PQAABWqSURBVDb96NNzCrl9/ibi03J57+5hhASVusar02m1z/cYCx7aBVIp5V5sU6MvcDjx9hTm3RHO0NMvxpuwDbJPaLONUsot2aZG3y7Al8/vH1H+VZ8OfAsI9Bx7zsullFINzTY1eqDiS/sd+BY6D4GmjedqT0opVVdsFfQVSjsCgTp0sFLKPblH0OdngU/A2ZdTSikbsn/QO51QmA2+zRq6JEop1SDsH/SF2da9jwa9Uso92T/o87Ose5+mDVsOpZRqIPYP+gJX0PtqG71Syj25T9Br041Syk3ZP+i16UYp5ebsH/QFroOx2utGKeWm3CDotelGKeXe7B/0+ZnWvQa9UspN2T/otelGKeXmqhT0IjJeRPaJyEERmV3O/G4i8p2IbBeRdSISVGreP0Rkl4jsEZFXRKSCkcfqSXHTjbcejFVKuaezBr2IeAKvA1cB/YBpInL6CGEvAouMMQOBp4DnXOteDIwABgIDgKHA6DorfVXkZ4KXP3jaZkRmpZSqlqrU6COAg8aYaGNMAfARcN1py/QD1rgery013wB+gA/gC3gDibUtdLUU6Dg3Sin3VpWg7wwcK/U81jWttG3AJNfjG4AAEWljjPkFK/iPu25fG2P2nP4CInKviESKSGRSUlJ196FyBVnah14p5dbq6mDsH4HRIvIrVtNMHOAQkZ5AXyAI68vhMhEZefrKxpi5xphwY0x4u3bt6qhILgXZOkSxUsqtVaXhOg7oUup5kGtaCWNMPK4avYg0A240xqSJyD3ABmNMlmveSuAi4Ic6KHvV5GdqjV4p5daqUqPfDPQSke4i4gPcDCwrvYCItBWR4m09CixwPT6KVdP3EhFvrNr+GU039aogS9volVJu7axBb4wpAh4EvsYK6Y+NMbtE5CkRmehabAywT0T2A4HAs67pS4BDwA6sdvxtxpjldbsLZ1GQrSdLKaXcWpX6HBpjvgK+Om3aE6UeL8EK9dPXcwC/qWUZayc/S4NeKeXW3OPMWG26UUq5MXsHvTFQkKk1eqWUW7N30BfmgnFqrxullFuzd9CXDGim/eiVUu7L5kFfPESx1uiVUu7L3kGfrxcdUUopewe9jkWvlFJ2D3qt0SullAa9UkrZnL2DvriNXptulFJuzN5BrzV6pZTSoFdKKbuzd9DnZ4GHN3j5NHRJlFKqwdg76HVAM6WUsnvQZ+llBJVSbs/eQa+XEVRKKZsHvTbdKKWU3YNery6llFL2Dvr8LG26UUq5PXsHfUG2jkWvlHJ7Ng96PRirlFI2D/psbaNXSrk9+wZ9UQE4CrTXjVLK7dk36HWcG6WUAjTolVLK9uwb9DoWvVJKAXYO+uLrxWqNXinl5mwc9JnWvQa9UsrN2Tfoi5tutB+9UsrN2Tfoi5tutI1eKeXmbBz0xTV6HQJBKeXe7Bv0+cVt9Np0o5Ryb/YN+oJsEA/w9m/okiilVIOycdC7LiMo0tAlUUqpBmXzoNdmG6WUqlLQi8h4EdknIgdFZHY587uJyHcisl1E1olIkGv6pSKytdQtT0Sur+udKFd+lva4UUopqhD0IuIJvA5cBfQDpolIv9MWexFYZIwZCDwFPAdgjFlrjAkzxoQBlwE5wDd1WP6KaY1eKaWAqtXoI4CDxphoY0wB8BFw3WnL9APWuB6vLWc+wE3ASmNMTk0LWy06Fr1SSgFVC/rOwLFSz2Nd00rbBkxyPb4BCBCRNqctczPwYXkvICL3ikikiEQmJSVVoUhVkJ+llxFUSinq7mDsH4HRIvIrMBqIAxzFM0WkIxACfF3eysaYucaYcGNMeLt27eqmRNp0o5RSAHhVYZk4oEup50GuaSWMMfG4avQi0gy40RiTVmqRKcBnxpjC2hW3GgqytOlGKaWoWo1+M9BLRLqLiA9WE8yy0guISFsRKd7Wo8CC07YxjQqabeqN9rpRSimgCkFvjCkCHsRqdtkDfGyM2SUiT4nIRNdiY4B9IrIfCASeLV5fRIKxfhF8X6clr4zTAUW5WqNXSimq1nSDMeYr4KvTpj1R6vESYEkF68Zw5sHb+qWXEVRKqRL2PDNWx6JXSqkS9gz6krHotXulUkrZNOj1MoJKKVXMpkFffGFwbbpRSil7Bn1xG712r1RKKZsGvV5GUCmlStg86LXpRiml7Bn02nSjlFIl7Bn0xTV6b63RK6WUTYM+2wp5D3vunlJKVYc9kzA/U5ttlFLKxZ5BX5CtB2KVUsrFpkGvY9ErpVQxewa9XkZQKaVK2DPo9TKCSilVwsZBr003SikFtg16PRirlFLF7Bn02kavlFIl7Bf0xmjTjVJKlWK/oC/MAYw23SillIv9gl4HNFNKqTLsF/Q6Fr1SSpVh46DXphullAI7Br023SilVBn2C/qSC4Nr0CulFNgy6DOtew16pZQC7Bj02nSjlFJl2C/oS5pu9GCsUkqBLYNeu1cqpVRp9gx6Lz/w9Grokiil1HnBfkGfr2PRK6VUafar9uqAZkpVS2FhIbGxseTl5TV0UVQV+Pn5ERQUhLe3d5XXsWHQZ2vQK1UNsbGxBAQEEBwcjIg0dHFUJYwxJCcnExsbS/fu3au8ng2bbjK1a6VS1ZCXl0ebNm005BsBEaFNmzbV/vVVpaAXkfEisk9EDorI7HLmdxOR70Rku4isE5GgUvO6isg3IrJHRHaLSHC1Slhd2nSjVLVpyDceNflbnTXoRcQTeB24CugHTBORfqct9iKwyBgzEHgKeK7UvEXAP40xfYEI4ES1S1kdehlBpZQqoyo1+gjgoDEm2hhTAHwEXHfaMv2ANa7Ha4vnu74QvIwx3wIYY7KMMTl1UvKK6GUElVKqjKoEfWfgWKnnsa5ppW0DJrke3wAEiEgboDeQJiKfisivIvJP1y+EMkTkXhGJFJHIpKSk6u9Fadp0o5StNWum/9/VVVe9bv4IvCYidwLrgTjA4dr+SGAQcBT4H3AnML/0ysaYucBcgPDwcFPjUpRcL1abbpSqib8t38Xu+Iw63Wa/Ts158tr+dbrN80FRURFeXo2j42JVavRxQJdSz4Nc00oYY+KNMZOMMYOAx13T0rBq/1tdzT5FwOfA4DopeXmK8sFZpL1ulGpEZs+ezeuvv17yfM6cOTzzzDOMHTuWwYMHExISwhdffFGlbWVlZVW43qJFixg4cCChoaHcfvvtACQmJnLDDTcQGhpKaGgoP//8MzExMQwYMKBkvRdffJE5c+YAMGbMGB5++GHCw8N5+eWXWb58OcOGDWPQoEFcfvnlJCYmlpTjrrvuIiQkhIEDB7J06VIWLFjAww8/XLLdefPm8cgjj9T4fasWY0ylN6xaeTTQHfDBaqbpf9oybQEP1+Nngadcjz1dy7dzPV8IPFDZ6w0ZMsTUWNZJY55sbsyG/9Z8G0q5md27dzfo62/ZssWMGjWq5Hnfvn3N0aNHTXp6ujHGmKSkJNOjRw/jdDqNMcY0bdq0wm0VFhaWu97OnTtNr169TFJSkjHGmOTkZGOMMVOmTDEvvfSSMcaYoqIik5aWZg4fPmz69+9fss1//vOf5sknnzTGGDN69Ghz3333lcxLSUkpKde8efPMrFmzjDHG/PnPfza///3vyyyXmZlpLrjgAlNQUGCMMeaiiy4y27dvr+7bZYwp/28GRJoKcvWsvzuMMUUi8iDwtSu4FxhjdonIU64NLwPGAM+JiMFqunnAta5DRP4IfCdWn6AoYF6tv50qomPRK9XoDBo0iBMnThAfH09SUhKtWrWiQ4cOPPLII6xfvx4PDw/i4uJITEykQ4cOlW7LGMNjjz12xnpr1qxh8uTJtG3bFoDWrVsDsGbNGhYtWgSAp6cnLVq0IDU1tdLXmDp1asnj2NhYpk6dyvHjxykoKCg5iWn16tV89NFHJcu1atUKgMsuu4wVK1bQt29fCgsLCQkJqea7VTNVamAyxnwFfHXatCdKPV4CLKlg3W+BgbUoY9UVD1GsTTdKNSqTJ09myZIlJCQkMHXqVBYvXkxSUhJRUVF4e3sTHBxcpZOEarpeaV5eXjidzpLnp6/ftOmpY4APPfQQs2bNYuLEiaxbt66kiaciM2fO5O9//zt9+vThrrvuqla5asNeZ8bm64XBlWqMpk6dykcffcSSJUuYPHky6enptG/fHm9vb9auXcuRI0eqtJ2K1rvsssv45JNPSE5OBiAlJQWAsWPH8uabbwLgcDhIT08nMDCQEydOkJycTH5+PitWrKj09Tp3tjohvvvuuyXTx40bV+a4Q/GvhGHDhnHs2DE++OADpk2bVtW3p9bsFfQlTTfaj16pxqR///5kZmbSuXNnOnbsyK233kpkZCQhISEsWrSIPn36VGk7Fa3Xv39/Hn/8cUaPHk1oaCizZs0C4OWXX2bt2rWEhIQwZMgQdu/ejbe3N0888QQRERGMGzeu0teeM2cOkydPZsiQISXNQgB//etfSU1NZcCAAYSGhrJ27dqSeVOmTGHEiBElzTnnglht+OeP8PBwExkZWbOVd38BH98B9/0MgfbrzqVUfdizZw99+/Zt6GK4jQkTJvDII48wduzYGm+jvL+ZiEQZY8LLW95eNXptulFKnafS0tLo3bs3/v7+tQr5mmgcvf2rSi8jqJRb2LFjR0lf+GK+vr5s3LixgUp0di1btmT//v0N8to2DXqt0StlZyEhIWzdurWhi9Fo2K/pxsMLvHwbuiRKKXXesFfQF19dSsfWVkqpEjYLeh25UimlTmevoNfLCCql1BnsFfR6YXClGp20tDTeeOONaq939dVXk5aWVg8lsh/79brRHjdK1dzK2ZCwo2632SEErnq+wtnFQX///feXmX628d6/+uqrCuedD86n8ertV6PXywgq1ajMnj2bQ4cOERYWxtChQxk5ciQTJ06kXz/r0tTXX389Q4YMoX///sydO7dkveDgYE6ePElMTAx9+/blnnvuoX///lxxxRXk5uZW+Hrz5s1j6NChhIaGcuONN5KTY13dtLyx6aH8cezvvPNOliw5NY5j8VWv1q1bV+Xyr1q1isGDBxMaGsrYsWNxOp306tWL4qvsOZ1OevbsSa2vugdnH4/+XN9qNR79SyHGLL2n5usr5YYaejz60uO/r1271jRp0sRER0eXzC8eOz4nJ8f079/fnDx50hhjTLdu3UxSUpI5fPiw8fT0NL/++qsxxpjJkyeb9957r8LXK17fGGMef/xx88orrxhjyh+bvqJx7KdPn24++eSTku0Uj5Ff1fKfOHHCBAUFlSxXvMycOXNKyvD111+bSZMmlbsP1R2P3mY1eu11o1RjFxERUTKuO8Arr7xCaGgow4cP59ixYxw4cOCMdbp3705YWBgAQ4YMISYmpsLt79y5k5EjRxISEsLixYvZtWsXYI1Nf9999wGnxqavaBz72pZ/w4YNjBo1qmS54u3OmDGjZHz8BQsW1NlQxudHA1JdKcjWXjdKNXKlx3tft24dq1ev5pdffqFJkyaMGTOm3PHlfX1PnSTp6elZadPNnXfeyeeff05oaCjvvPMO69atq3YZS49Z73Q6KSgoqFX5i3Xp0oXAwEDWrFnDpk2bWLx4cbXLVh771OgdRVCUpzV6pRqZgIAAMjMzy52Xnp5Oq1ataNKkCXv37mXDhg21fr3MzEw6duxIYWFhmSAtb2z6isaxDw4OJioqCoBly5ZRWFhYrfIPHz6c9evXc/jw4TLbBeviJLfddhuTJ0/G09Oz1vsLdgp6vYygUo1SmzZtGDFiBAMGDOBPf/pTmXnjx4+nqKiIvn37Mnv2bIYPH17r13v66acZNmwYI0aMKDPWfHlj01c0jv0999zD999/T2hoKL/88kuZWnxVyt+uXTvmzp3LpEmTCA0NLXN5wokTJ5ZcXLyu2Gc8+txUWPEIDLoNel5e9wVTyqZ0PPrzS2RkJI888gg//PBDhctUdzx6+7TR+7eCye80dCmUUqrGnn/+ed588806a5svZp+mG6WUKuWBBx4gLCyszG3hwoUNXaxKzZ49myNHjnDJJZfU6XbtU6NXStWYMQax2aivpS/ObSc1aW7XGr1Sbs7Pz4/k5OQaBYg6t4wxJCcn4+fnV631tEavlJsLCgoiNja2bk61V/XOz8+PoKCgaq2jQa+Um/P29i5zJqeyH226UUopm9OgV0opm9OgV0opmzvvzowVkSTgSC020RY4WUfFaUx0v92L7rd7qcp+dzPGtCtvxnkX9LUlIpEVnQZsZ7rf7kX3273Udr+16UYppWxOg14ppWzOjkE/9+yL2JLut3vR/XYvtdpv27XRK6WUKsuONXqllFKlaNArpZTN2SboRWS8iOwTkYMiMruhy1OfRGSBiJwQkZ2lprUWkW9F5IDrvlVDlrGuiUgXEVkrIrtFZJeI/N413e777Scim0Rkm2u//+aa3l1ENro+7/8TEZ+GLmt9EBFPEflVRFa4nrvLfseIyA4R2Soika5pNf6s2yLoRcQTeB24CugHTBORfg1bqnr1DjD+tGmzge+MMb2A71zP7aQI+IMxph8wHHjA9Te2+37nA5cZY0KBMGC8iAwHXgBeMsb0BFKBuxuwjPXp98CeUs/dZb8BLjXGhJXqP1/jz7otgh6IAA4aY6KNMQXAR8B1DVymemOMWQ+knDb5OuBd1+N3gevPaaHqmTHmuDFmi+txJtY/f2fsv9/GGJPleurtuhngMmCJa7rt9htARIKAa4C3Xc8FN9jvStT4s26XoO8MHCv1PNY1zZ0EGmOOux4nAIENWZj6JCLBwCBgI26w367mi63ACeBb4BCQZowpci1i18/7f4A/A07X8za4x36D9WX+jYhEici9rmk1/qzrePQ2ZIwxImLLfrMi0gxYCjxsjMkoffk7u+63McYBhIlIS+AzoE8DF6neicgE4IQxJkpExjR0eRrAJcaYOBFpD3wrIntLz6zuZ90uNfo4oEup50Guae4kUUQ6ArjuTzRweeqciHhjhfxiY8ynrsm23+9ixpg0YC1wEdBSRIoranb8vI8AJopIDFZT7GXAy9h/vwEwxsS57k9gfblHUIvPul2CfjPQy3VE3ge4GVjWwGU615YB012PpwNfNGBZ6pyrfXY+sMcY8+9Ss+y+3+1cNXlExB8Yh3V8Yi1wk2sx2+23MeZRY0yQMSYY6/95jTHmVmy+3wAi0lREAoofA1cAO6nFZ902Z8aKyNVYbXqewAJjzLMNXKR6IyIfAmOwhi5NBJ4EPgc+BrpiDfM8xRhz+gHbRktELgF+AHZwqs32Max2ejvv90CsA2+eWBWzj40xT4nIBVg13dbAr8Btxpj8hitp/XE13fzRGDPBHfbbtY+fuZ56AR8YY54VkTbU8LNum6BXSilVPrs03SillKqABr1SStmcBr1SStmcBr1SStmcBr1SStmcBr1SStmcBr1SStnc/wM0NVEPXk9cBQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WXq3K5IKMg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8849ea-bf4e-40da-b117-bac1e7ed5911"
      },
      "source": [
        "## evaluate on the test set.\n",
        "## you should get acc higher than 0.98\n",
        "model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "## When we used MLP for classification of images, we got 0.98 on the test set using 178,110 parameters.\n",
        "## When we used CNN for classification of images, We get 0.99 on the test set using only 17,578 parameters !!"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11141573637723923, 0.9879999756813049]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi4rsO393tWV"
      },
      "source": [
        "### 2. Classification on CIFAR-10 dataset (Kaggle Competition!)\n",
        "#### - a. load dataset: https://keras.io/api/datasets/cifar10/\n",
        "#### - b. pre-processing\n",
        "#### - c. define your CNN model (Google it!) \n",
        "#### Batch Normalization (https://keras.io/api/layers/normalization_layers/batch_normalization/)\n",
        "####     Same Padding (https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "#### - d. Train your model\n",
        "#### - e. Tune hyperparamters of your model on the validation set\n",
        "#### - f. Evaluate your model on the test set.\n",
        "\n",
        "\\\n",
        "#### - GOAL : you should achieve accuracy higher than 0.75 with less than 100,000 parameters\n",
        "#### make your team name as \"date_name\" (ex. 20220307_WonbinKweon)  ('team'탭에 가면 변경가능)\n",
        "(https://www.kaggle.com/c/cifar-10-classification1234/host/all-submissions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Os84NuLRf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85651ec5-33b7-412a-c4ab-6f08d9bd0d4e"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Download CIFAR dataset\n",
        "(X_train, y_train), (X_test, y_test) =keras.datasets.cifar10.load_data()\n",
        "\n",
        "# calculate the sample mean and std\n",
        "mu = X_train.mean()\n",
        "# 0으로 나누는 것을 방지하기 위해서 매우 작은 값을 더해준다.\n",
        "sig = X_train.std()+0.000000001\n",
        "\n",
        "# normalize (z-score)\n",
        "X_train = (X_train - mu) / sig\n",
        "# print(X_train[0])\n",
        "\n",
        "# train set과 동일한 평균과 표준편차로 test_set도 변경해줘야한다.\n",
        "\n",
        "X_test = (X_test - mu) / sig # note! : use the same statistic with the training set!\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxR_8eB4TF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ccf15e-734e-47c2-9fe1-f482c7bae49c"
      },
      "source": [
        "## b. Model\n",
        "model = keras.Sequential(\n",
        "    [ \n",
        "      # conv 1\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      # conv 2\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      #  Pooling \n",
        "     layers.MaxPooling2D(\n",
        "       pool_size=(2, 2), strides=None, padding=\"same\" ),\n",
        "      # conv 1\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      # conv 2\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      #  Pooling \n",
        "     layers.MaxPooling2D(\n",
        "       pool_size=(2, 2), strides=None, padding=\"same\" ),\n",
        "     # conv 1\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      # conv 2\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      #  Pooling \n",
        "     layers.MaxPooling2D(\n",
        "       pool_size=(2, 2), strides=None, padding=\"same\" ),\n",
        "      # conv 1\n",
        "      layers.Conv2D(filters=16, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      # conv 2\n",
        "      layers.Conv2D(filters=16, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      #  Pooling \n",
        "     layers.MaxPooling2D(\n",
        "       pool_size=(2, 2), strides=None, padding=\"same\" ),\n",
        "      # conv 1\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      # conv 2\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1),padding=\"same\",input_shape=(32,32,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Activation('relu'),\n",
        "      #  Pooling \n",
        "     layers.MaxPooling2D(\n",
        "      pool_size=(2, 2), strides=None, padding=\"same\" ),\n",
        "     \n",
        "      layers.Flatten(),\n",
        "    #  hidden layer를 써도 됨\n",
        "       layers.Dense(100,activation='relu'),\n",
        "       layers.Dense(10,activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_95 (Conv2D)          (None, 32, 32, 48)        1344      \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 32, 32, 48)       192       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_94 (Activation)  (None, 32, 32, 48)        0         \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 32, 32, 48)        20784     \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 32, 32, 48)       192       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_95 (Activation)  (None, 32, 32, 48)        0         \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 16, 16, 48)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 16, 16, 32)        13856     \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_96 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_97 (Activation)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 8, 8, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_98 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_99 (Activation)  (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 4, 4, 16)          4624      \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 4, 4, 16)         64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_100 (Activation)  (None, 4, 4, 16)         0         \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 4, 4, 16)          2320      \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 4, 4, 16)         64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_101 (Activation)  (None, 4, 4, 16)         0         \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 2, 2, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 2, 2, 32)          4640      \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 2, 2, 32)         128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_102 (Activation)  (None, 2, 2, 32)         0         \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 2, 2, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 2, 2, 32)         128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_103 (Activation)  (None, 2, 2, 32)         0         \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 1, 1, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               3300      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,150\n",
            "Trainable params: 89,510\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlgu4MEk5n0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6323d1-8b35-40a2-bdb1-8fbde121f5b1"
      },
      "source": [
        "## Train\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "## compile\n",
        "# 러닝 rate / loss / optimaizer 머 쓸건지 정함\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) # keras.losses.MeanSq\n",
        "## fit\n",
        "hist = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1407/1407 [==============================] - 26s 17ms/step - loss: 0.1957 - accuracy: 0.9312 - val_loss: 1.0345 - val_accuracy: 0.7662\n",
            "Epoch 2/20\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1925 - accuracy: 0.9310 - val_loss: 0.9565 - val_accuracy: 0.7622\n",
            "Epoch 3/20\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1912 - accuracy: 0.9318 - val_loss: 1.0556 - val_accuracy: 0.7560\n",
            "Epoch 4/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1908 - accuracy: 0.9329 - val_loss: 0.8643 - val_accuracy: 0.7804\n",
            "Epoch 5/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1844 - accuracy: 0.9349 - val_loss: 0.9226 - val_accuracy: 0.7790\n",
            "Epoch 6/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1854 - accuracy: 0.9340 - val_loss: 0.9247 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1802 - accuracy: 0.9355 - val_loss: 1.0171 - val_accuracy: 0.7734\n",
            "Epoch 8/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1739 - accuracy: 0.9380 - val_loss: 0.9904 - val_accuracy: 0.7586\n",
            "Epoch 9/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1690 - accuracy: 0.9412 - val_loss: 1.1689 - val_accuracy: 0.7408\n",
            "Epoch 10/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1643 - accuracy: 0.9418 - val_loss: 0.9380 - val_accuracy: 0.7772\n",
            "Epoch 11/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1594 - accuracy: 0.9438 - val_loss: 0.9514 - val_accuracy: 0.7712\n",
            "Epoch 12/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1597 - accuracy: 0.9429 - val_loss: 1.0932 - val_accuracy: 0.7544\n",
            "Epoch 13/20\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1554 - accuracy: 0.9454 - val_loss: 1.0505 - val_accuracy: 0.7680\n",
            "Epoch 14/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1485 - accuracy: 0.9474 - val_loss: 0.9893 - val_accuracy: 0.7702\n",
            "Epoch 15/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1513 - accuracy: 0.9474 - val_loss: 0.9861 - val_accuracy: 0.7712\n",
            "Epoch 16/20\n",
            "1407/1407 [==============================] - 23s 17ms/step - loss: 0.1457 - accuracy: 0.9492 - val_loss: 0.9742 - val_accuracy: 0.7762\n",
            "Epoch 17/20\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1460 - accuracy: 0.9490 - val_loss: 1.0271 - val_accuracy: 0.7690\n",
            "Epoch 18/20\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1406 - accuracy: 0.9505 - val_loss: 1.0554 - val_accuracy: 0.7702\n",
            "Epoch 19/20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1371 - accuracy: 0.9519 - val_loss: 1.0765 - val_accuracy: 0.7750\n",
            "Epoch 20/20\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.1317 - accuracy: 0.9535 - val_loss: 1.0500 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot loss and accuracy to check if the model is converged.\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "train_accuracy = hist.history['accuracy']\n",
        "\n",
        "# x축을 epochs\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(np.arange(epochs),val_accuracy,label=\"val_accuracy\")\n",
        "plt.plot(np.arange(epochs),train_accuracy,label=\"train_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XJkLN3ApYiPO",
        "outputId": "7d15fef3-2b57-4082-c571-ddd75e0648ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKDGQd3k7gbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1173386-52c7-4c5c-a2aa-9ee1a0924fa2"
      },
      "source": [
        "## evaluate on the test set.\n",
        "## you should get acc higher than 0.75\n",
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0412 - accuracy: 0.7653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0412043333053589, 0.7652999758720398]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Submission for Kaggle\n",
        "import pandas as pd\n",
        "\n",
        "# predict results\n",
        "results = model.predict(X_test)\n",
        "\n",
        "# select the indix with the maximum probability\n",
        "results = np.argmax(results,axis = 1)\n",
        "\n",
        "results = pd.Series(results,name=\"Category\")\n",
        "\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,10001),name = \"Id\"),results],axis = 1)\n",
        "\n",
        "submission.to_csv(\"Cifar10_classification.csv\",index=False)"
      ],
      "metadata": {
        "id": "0Et7v9Av-Y7s"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MDaS6EPYbUOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}